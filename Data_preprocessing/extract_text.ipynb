{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Requirement already satisfied: pdfminer.six in /home/pratyush/miniconda3/envs/temenos/lib/python3.11/site-packages (20240706)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /home/pratyush/miniconda3/envs/temenos/lib/python3.11/site-packages (from pdfminer.six) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /home/pratyush/miniconda3/envs/temenos/lib/python3.11/site-packages (from pdfminer.six) (44.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/pratyush/miniconda3/envs/temenos/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/pratyush/miniconda3/envs/temenos/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Requirement already satisfied: PyPDF2 in /home/pratyush/miniconda3/envs/temenos/lib/python3.11/site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfminer.six\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def extract_text_from_pdfs(pdf_directory):\n",
    "    data = []\n",
    "    \n",
    "    for filename in os.listdir(pdf_directory):\n",
    "        if filename.endswith('.pdf'):\n",
    "            filepath = os.path.join(pdf_directory, filename)\n",
    "            \n",
    "            # Error handling\n",
    "            try:\n",
    "                text = extract_text(filepath)\n",
    "                \n",
    "                # Parse the filename to extract ticker and year\n",
    "                parts = filename.split('_')\n",
    "                ticker = parts[1]\n",
    "                year = parts[2].split('.')[0]  # Remove the .pdf extension\n",
    "                \n",
    "                data.append({\n",
    "                    'filename': filename,\n",
    "                    'ticker': ticker,\n",
    "                    'year': year,\n",
    "                    'text': text\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}. Error: {e}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_to_csv(data, output_filename):\n",
    "    with open(output_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['filename', 'ticker', 'year', 'text']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "pdf_directory = './tests'\n",
    "output_csv = 'abc.csv'\n",
    "\n",
    "data = extract_text_from_pdfs(pdf_directory)\n",
    "save_to_csv(data, output_csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import PyPDF2\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def pdf_to_text(pdf_path):\n",
    "    \"\"\"\n",
    "    Convert a PDF file to a list of lists containing lines of text from each page.\n",
    "\n",
    "    Args:\n",
    "    - pdf_path (str): The path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of lists containing lines of text from each page. Returns None if an exception occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            pdf = PyPDF2.PdfReader(file)\n",
    "            page_lines_list = []\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                lines = [\n",
    "                    re.sub(r\"[\\d]+|page\", \"\", line.strip().lower())\n",
    "                    for line in page_text.split(\"\\n\")\n",
    "                    if line.strip()\n",
    "                ]\n",
    "                page_lines_list.append(lines)\n",
    "            return page_lines_list\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_repeating_elements(all_line_list):\n",
    "    \"\"\"\n",
    "    Find repeating elements across all pages of a PDF.\n",
    "\n",
    "    Args:\n",
    "    - all_line_list (list): A list of lists containing lines of text from each page.\n",
    "\n",
    "    Returns:\n",
    "    - set: A set containing elements that appear more than once.\n",
    "    \"\"\"\n",
    "    flat_list = [elem for sublist in all_line_list for elem in sublist]\n",
    "    counts = Counter(flat_list)\n",
    "    repeating_elements = {key for key, val in counts.items() if val > 1}\n",
    "    return repeating_elements\n",
    "\n",
    "\n",
    "def remove_elements_from_list(all_line_list, elements_to_remove):\n",
    "    \"\"\"\n",
    "    Remove specified elements from all pages of a PDF.\n",
    "\n",
    "    Args:\n",
    "    - all_line_list (list): A list of lists containing lines of text from each page.\n",
    "    - elements_to_remove (set): A set containing elements to be removed.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of lists after removing the specified elements.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        [item for item in sublist if item not in elements_to_remove]\n",
    "        for sublist in all_line_list\n",
    "    ]\n",
    "\n",
    "\n",
    "def pdf_to_text_pipeline(pdf_path):\n",
    "    \"\"\"\n",
    "    Pipeline to convert a PDF to a single text string after cleaning.\n",
    "\n",
    "    Args:\n",
    "    - pdf_path (str): The path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    - str: A string containing all text after cleaning.\n",
    "    \"\"\"\n",
    "    page_lines_list = pdf_to_text(pdf_path)\n",
    "    repeating_elements = find_repeating_elements(page_lines_list)\n",
    "    cleaned_all_line_list = remove_elements_from_list(\n",
    "        page_lines_list, repeating_elements\n",
    "    )\n",
    "    text = \" \".join([\" \".join(sublist) for sublist in cleaned_all_line_list])\n",
    "    return text\n",
    "\n",
    "\n",
    "def process_pdfs_in_directory(directory, output_csv):\n",
    "    \"\"\"\n",
    "    Process all PDF files in a directory and save the content to a CSV file.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): The path to the directory containing PDF files.\n",
    "    - output_csv (str): The path to the output CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - None: Writes to the CSV file.\n",
    "    \"\"\"\n",
    "    with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        fieldnames = [\"filename\", \"ticker\", \"year\", \"content\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith(\".pdf\"):\n",
    "                print(f\"Processing {file}...\")\n",
    "                filepath = os.path.join(directory, file)\n",
    "                content = pdf_to_text_pipeline(filepath)\n",
    "                if content:\n",
    "                    _, ticker, year = file.rstrip(\".pdf\").split(\"_\")\n",
    "                    writer.writerow(\n",
    "                        {\n",
    "                            \"filename\": file,\n",
    "                            \"ticker\": ticker,\n",
    "                            \"year\": year,\n",
    "                            \"content\": content,\n",
    "                        }\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ABT_archived_1736098442.16996.pdf...\n",
      "Processing ABT_most_recent.pdf...\n",
      "Processing ABT_archived_1736098471.2136264.pdf...\n"
     ]
    }
   ],
   "source": [
    "process_pdfs_in_directory('./tests', 'a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import requests\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib.request\n",
    "import yesg\n",
    "\n",
    "def getting_ESG_scores():\n",
    "    \"\"\"\n",
    "    This function gets the ESG scores for the S&P 500 companies and saves them in a csv file.\n",
    "    Return: dataframe with the ESG scores per year per company\n",
    "    \"\"\"\n",
    "    # Getting resources from Wikipedia\n",
    "    resource = requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    # Parsing the resources\n",
    "    soup = bs.BeautifulSoup(resource.text, 'html.parser')\n",
    "    # Finding the table with the tickers\n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "\n",
    "    # Creating an empty list for the tickers\n",
    "    tickers = []\n",
    "    # Finding all the rows in the table\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text\n",
    "        tickers.append(ticker)\n",
    "    # Removing the \\n from the tickers\n",
    "    tickers = [s.replace('\\n', '') for s in tickers]\n",
    "\n",
    "\n",
    "    # Getting the ESG scores for each ticker\n",
    "    dataframes = []\n",
    "    i = 0\n",
    "    tickers = ['TEMN']\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            df = pd.DataFrame(yesg.get_historic_esg(ticker))\n",
    "            i += 1\n",
    "            print(ticker, i)\n",
    "            df['Company_Symbol'] = ticker\n",
    "            dataframes.append(df)\n",
    "        except:\n",
    "            pass\n",
    "    # Concatenating the dataframes\n",
    "    df = pd.concat(dataframes)\n",
    "\n",
    "    df['timestamp'] = df.index\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "\n",
    "    # Removing the non-values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Setting dataframe index to timestamp\n",
    "    df['timestamp'] = df.index\n",
    "\n",
    "    # Resetting the index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Setting the timestamp as datetime format\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "\n",
    "    # Adding the year column to dataframe for calculating the average ESG score per year\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "\n",
    "    # Grouping the dataframe by year and ticker\n",
    "    cleaned_df = df.groupby(['year', 'Company_Symbol']).mean()\n",
    "\n",
    "    # Removing the timestamp column\n",
    "    cleaned_df.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "    # Creating a csv file with the results\n",
    "    cleaned_df.to_csv('./SP500_EGS_Score_avarage_per_year.csv')\n",
    "\n",
    "    esg_score = pd.read_csv('./SP500_EGS_Score_avarage_per_year.csv')\n",
    "\n",
    "    return esg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
      "Collecting yesg\n",
      "  Downloading yesg-2.1.1.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: yesg\n",
      "  Building wheel for yesg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for yesg: filename=yesg-2.1.1-py3-none-any.whl size=6105 sha256=9a0a68fbc1ccf1471ca53c8c733d49ac4f0e1d6308b964c5e649ecfe6a0dfbbc\n",
      "  Stored in directory: /home/pratyush/.cache/pip/wheels/78/8d/48/f5e8ff0315a46301e15c68371e297b460b33e1c846117725bc\n",
      "Successfully built yesg\n",
      "Installing collected packages: yesg\n",
      "Successfully installed yesg-2.1.1\n"
     ]
    }
   ],
   "source": [
    "! pip install yesg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error has occurred. The ticker symbol might be wrong or you might need to wait to continue.\n",
      "TEMN 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Company_Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year, Company_Symbol]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getting_ESG_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to merged_averaged_scores_with_sector.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the averaged scores per company\n",
    "averaged_scores_file = \"averaged_scores_per_company.csv\"\n",
    "averaged_scores_df = pd.read_csv(averaged_scores_file)\n",
    "\n",
    "# Load the sector data\n",
    "sector_file = \"sector.csv\"\n",
    "sector_df = pd.read_csv(sector_file)\n",
    "\n",
    "# Merge the two DataFrames based on the company name (or a common column)\n",
    "# Assuming the common column is 'Company_Symbol' in both files\n",
    "merged_df = pd.merge(\n",
    "    averaged_scores_df,  # Left DataFrame\n",
    "    sector_df,           # Right DataFrame\n",
    "    on=\"Company_Symbol\", # Common column to merge on\n",
    "    how=\"left\"           # Keep all rows from the left DataFrame\n",
    ")\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "output_file_path = \"merged_averaged_scores_with_sector.csv\"\n",
    "merged_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined_historical_and_predicted_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Company_Symbol</th>\n",
       "      <th>Total-Score</th>\n",
       "      <th>E-Score</th>\n",
       "      <th>S-Score</th>\n",
       "      <th>G-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>A</td>\n",
       "      <td>17.143333</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>9.416667</td>\n",
       "      <td>6.856667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>A</td>\n",
       "      <td>16.598000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>6.288000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>A</td>\n",
       "      <td>15.330000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>8.650000</td>\n",
       "      <td>6.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>A</td>\n",
       "      <td>14.440000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>7.535000</td>\n",
       "      <td>6.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>A</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>6.230000</td>\n",
       "      <td>3.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025</td>\n",
       "      <td>A</td>\n",
       "      <td>10.472743</td>\n",
       "      <td>1.090920</td>\n",
       "      <td>5.702196</td>\n",
       "      <td>3.592605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2026</td>\n",
       "      <td>A</td>\n",
       "      <td>9.583108</td>\n",
       "      <td>0.996409</td>\n",
       "      <td>4.879913</td>\n",
       "      <td>3.395365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2027</td>\n",
       "      <td>A</td>\n",
       "      <td>8.693097</td>\n",
       "      <td>0.905262</td>\n",
       "      <td>3.764917</td>\n",
       "      <td>3.337786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2028</td>\n",
       "      <td>A</td>\n",
       "      <td>5.613129</td>\n",
       "      <td>1.531027</td>\n",
       "      <td>2.459908</td>\n",
       "      <td>1.078171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2029</td>\n",
       "      <td>A</td>\n",
       "      <td>4.725952</td>\n",
       "      <td>1.433372</td>\n",
       "      <td>1.932190</td>\n",
       "      <td>0.740594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year Company_Symbol  Total-Score   E-Score   S-Score   G-Score\n",
       "0  2020              A    17.143333  0.870000  9.416667  6.856667\n",
       "1  2021              A    16.598000  0.870000  9.440000  6.288000\n",
       "2  2022              A    15.330000  0.340000  8.650000  6.340000\n",
       "3  2023              A    14.440000  0.730000  7.535000  6.180000\n",
       "4  2024              A    11.360000  1.190000  6.230000  3.930000\n",
       "5  2025              A    10.472743  1.090920  5.702196  3.592605\n",
       "6  2026              A     9.583108  0.996409  4.879913  3.395365\n",
       "7  2027              A     8.693097  0.905262  3.764917  3.337786\n",
       "8  2028              A     5.613129  1.531027  2.459908  1.078171\n",
       "9  2029              A     4.725952  1.433372  1.932190  0.740594"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temenos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
